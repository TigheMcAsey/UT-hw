\documentclass[10.5pt]{article}
\usepackage{amsmath, amsfonts, amssymb,amsthm}
\usepackage[includeheadfoot]{geometry} % For page dimensions
\usepackage{fancyhdr}
\usepackage{enumerate} % For custom lists
\usepackage{xcolor}

\fancyhf{}
\lhead{MAT1600 hw2}
\rhead{Tighe McAsey - 1008309420}
\pagestyle{fancy}

% Page dimensions
\geometry{a4paper, margin=1in}

\theoremstyle{definition}
\newtheorem{pb}{}

% Commands:

\newcommand{\set}[1]{\{#1\}}
\newcommand{\abs}[1]{\lvert#1\rvert}
\newcommand{\norm}[1]{\lvert\lvert#1\rvert\rvert}
\newcommand{\tand}{\text{ and }}
\newcommand{\tor}{\text{ or }}

\begin{document}
    \begin{pb}\textbf{(Durrett 2.2.2)}
        We assume that \(r\) is a real valued function, i.e. that \(r(0) \in \mathbb{R}\) is not infinity. Then
        \begin{align*}
            0 \leq E\left[\left(\frac{S_n}{n}\right)^2\right] = \frac{1}{n^2}\left(\sum_1^n E X_j^2 + 2\sum_{\substack{1 \leq j \leq n \\ 1 \leq i < j}}EX_iX_j\right) &\leq \frac{1}{n^2}\left(nr(0) + 2\sum_{\substack{1 \leq j \leq n \\ 1 \leq i < j}}\abs{r(i-j)}\right) \\ &= \frac{r(0)}{n} + \frac{2}{n^2}\left(\sum_{j=1}^{n-1}(n-j)\abs{r(j)}\right)
        \end{align*}
        The term \(r(0)/n \to 0\), so it suffices to check that \(\frac{1}{n^2}\left(\sum_{j=1}^{n-1}(n-j)\abs{r(j)}\right) \to 0\). So take \(\epsilon > 0\), then for \(N \in \mathbb{N}\) we have \(j \geq N\) implies \(\abs{r(j)} < \epsilon/2\), then for \(M > N\),
        \begin{align*}
            \frac{1}{M^2}\sum_{j=N}^{M-1}(M-j)\abs{r(j)} < \frac{1}{M^2}(M-N-1)(M-N) \frac{\epsilon}{2} \leq \epsilon/2
        \end{align*}
        Now we can take \(M\) sufficiently large so that \(\frac{1}{M}\sum_1^{N-1}\abs{r(j)} < \epsilon/2\), then combining these inequalities, for any \(K \geq M\) we get
        \begin{align*}
            \frac{1}{K^2}\sum_1^{K-1}(K-j)\abs{r(j)} &= \frac{1}{K^2}\sum_N^{K-1}(K-j)\abs{r(j)} + \frac{1}{K^2}\sum_1^{N-1}(K-j)\abs{r(j)} < \epsilon/2 + \frac{1}{K}\sum_1^{N-1}\abs{r(j)} \\
            & \leq \epsilon/2 + \frac{1}{M}\sum_1^{N-1}\abs{r(j)} < \epsilon
        \end{align*}
        So indeed by squeeze theorem we find that \(E\left[\left(\frac{S_n}{n}\right)^2\right] \overset{L^2}{\to} 0\), and \(L^2\) convergence implies convergence in probability. \qed
    \end{pb}
    \begin{pb}\textbf{(Durrett 2.2.8)}
        In order to invoke the weak law of traingular arrays, we need to check the conditions.
        
        \textbf{(i) - \(\mathbf{\sum_1^n P(X_k>b_n) \to 0}\).}
        \begin{align*}
            P(X_k > b_n) &= \sum_{m(n)}^\infty p_j = \leq 2^{-m(n)}\sum_0^\infty \frac{1}{2^j(m(n)+j+1)(m(n)+j)} \leq 2^{-m(n)}m(n)^{-3/2}\frac{1}{\sqrt{m(n)}}\sum_0^\infty 2^{-j} \\&< \frac{2}{n\sqrt{m(n)}}
        \end{align*}
        So that
        \begin{align*}
            \sum_1^n P(X_k > b_n) < \frac{2}{\sqrt{m(n)}} \overset{n\to\infty}{\longrightarrow} 0
        \end{align*}

        \textbf{(ii) - \(\mathbf{\frac{1}{b_n^2}\sum_1^nE\overline{X}_{n,k}^2 \to 0}\)}, where \(\overline{X}_{n,k} = X_k1_{\set{\abs{X_k}\leq b_n}}\)
        \begin{align*}
            E\overline{X}_{n,k}^2 &= \left(\sum_1^{2^{m(n)}}p_k(2^k-1)-p_0\right)^2 = p_0^2 - 2p_0\left(\sum_1^{2^{m(n)}}\frac{1}{k(k+1)}-p_k\right) + \left(\sum_1^{2^{m(n)}}p_k(2^k-1)\right)^2 \\
            &\leq p_0^2 + \left(\sum_1^{2^{m(n)}}\frac{1}{k(k+1)} - p_k\right)^2 \leq p_0^2 + \left(\sum_1^{2^{m(n)}}\frac{1}{k(k+1)}\right)^2 \leq 1 + 1 = 2
        \end{align*}
        And hence,
        \begin{align*}
            \frac{1}{b_n^2}\sum_1^nE\overline{X}_{n,k}^2 \leq \frac{2n}{b_n^2} = \frac{2n}{2^{-2m(n)}} < \frac{2m(n)^{3/2}}{2^{-m(n)}} \overset{n \to \infty}{\longrightarrow} 0
        \end{align*}
        Now we want to obtain workable expressions to explain the asymptotic behaviour, we obtain the following expression for \(\sum_1^n E \overline{X}_{n,k}\)
    \end{pb}
\end{document}